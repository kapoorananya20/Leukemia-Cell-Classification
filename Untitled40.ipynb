{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed0e200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2766 images belonging to 4 classes.\n",
      "Found 814 images belonging to 4 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\Ananya\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ananya\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ananya\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\Ananya\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ananya\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "86/86 [==============================] - 86s 946ms/step - loss: 1.3597 - accuracy: 0.3299 - val_loss: 1.3384 - val_accuracy: 0.4487\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 75s 870ms/step - loss: 1.3476 - accuracy: 0.3328 - val_loss: 1.3116 - val_accuracy: 0.4487\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 73s 845ms/step - loss: 1.3462 - accuracy: 0.3508 - val_loss: 1.2985 - val_accuracy: 0.4487\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 79s 907ms/step - loss: 1.3060 - accuracy: 0.3530 - val_loss: 1.2251 - val_accuracy: 0.2450\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 91s 1s/step - loss: 1.0989 - accuracy: 0.5263 - val_loss: 0.9204 - val_accuracy: 0.6112\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 87s 1s/step - loss: 0.8544 - accuracy: 0.6200 - val_loss: 0.7677 - val_accuracy: 0.6650\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 79s 904ms/step - loss: 0.7996 - accuracy: 0.6357 - val_loss: 0.7562 - val_accuracy: 0.6488\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 78s 903ms/step - loss: 0.7908 - accuracy: 0.6320 - val_loss: 0.7608 - val_accuracy: 0.6525\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 79s 918ms/step - loss: 0.8085 - accuracy: 0.6383 - val_loss: 0.8591 - val_accuracy: 0.5763\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 95s 1s/step - loss: 0.7750 - accuracy: 0.6547 - val_loss: 0.7305 - val_accuracy: 0.6675\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 97s 1s/step - loss: 0.7372 - accuracy: 0.6807 - val_loss: 0.7320 - val_accuracy: 0.6625\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 70s 811ms/step - loss: 0.7064 - accuracy: 0.6975 - val_loss: 0.7950 - val_accuracy: 0.6450\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 42s 485ms/step - loss: 0.6642 - accuracy: 0.7176 - val_loss: 0.7016 - val_accuracy: 0.7063\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 42s 481ms/step - loss: 0.6337 - accuracy: 0.7195 - val_loss: 0.7085 - val_accuracy: 0.6950\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 38s 442ms/step - loss: 0.6437 - accuracy: 0.7260 - val_loss: 0.6356 - val_accuracy: 0.7100\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 39s 452ms/step - loss: 0.5927 - accuracy: 0.7381 - val_loss: 0.5606 - val_accuracy: 0.7638\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 37s 434ms/step - loss: 0.5603 - accuracy: 0.7604 - val_loss: 0.6129 - val_accuracy: 0.7425\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 41s 477ms/step - loss: 0.5877 - accuracy: 0.7557 - val_loss: 0.5202 - val_accuracy: 0.7750\n",
      "Epoch 19/20\n",
      "86/86 [==============================] - 46s 535ms/step - loss: 0.5295 - accuracy: 0.7901 - val_loss: 0.4806 - val_accuracy: 0.8125\n",
      "Epoch 20/20\n",
      "86/86 [==============================] - 40s 459ms/step - loss: 0.4967 - accuracy: 0.7933 - val_loss: 0.5918 - val_accuracy: 0.7538\n",
      "26/26 - 3s - loss: 0.5925 - accuracy: 0.7543 - 3s/epoch - 119ms/step\n",
      "\n",
      "Test accuracy: 0.7542997598648071\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "data_dir = r\"C:\\Users\\Ananya\\Desktop\\bi-space-2d\\original\"\n",
    "img_width, img_height = 150, 150\n",
    "input_shape = (img_width, img_height, 3)\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "\n",
    "classes = ['p-early', 'p-bengin', 'p-pre', 'p-pro']\n",
    "\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(data_dir, cls)\n",
    "    images = [f for f in os.listdir(cls_dir) if os.path.isfile(os.path.join(cls_dir, f))]\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    \n",
    "    split_idx = int(0.8 * len(images))\n",
    "    \n",
    "    \n",
    "    for img in images[:split_idx]:\n",
    "        src = os.path.join(cls_dir, img)\n",
    "        dst = os.path.join(train_dir, cls, img)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    \n",
    "    for img in images[split_idx:]:\n",
    "        src = os.path.join(cls_dir, img)\n",
    "        dst = os.path.join(test_dir, cls, img)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e69e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3166 images belonging to 4 classes.\n",
      "Found 1315 images belonging to 4 classes.\n",
      "Epoch 1/50\n",
      "98/98 [==============================] - 58s 577ms/step - loss: 1.3441 - accuracy: 0.3220 - val_loss: 1.3204 - val_accuracy: 0.2691\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 54s 547ms/step - loss: 1.0943 - accuracy: 0.5332 - val_loss: 0.9669 - val_accuracy: 0.4947\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 62s 632ms/step - loss: 0.7492 - accuracy: 0.6822 - val_loss: 0.5973 - val_accuracy: 0.7569\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 69s 698ms/step - loss: 0.6319 - accuracy: 0.7425 - val_loss: 0.5864 - val_accuracy: 0.7546\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 61s 618ms/step - loss: 0.5870 - accuracy: 0.7639 - val_loss: 0.5754 - val_accuracy: 0.7637\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 55s 564ms/step - loss: 0.5371 - accuracy: 0.7862 - val_loss: 0.5093 - val_accuracy: 0.7995\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 55s 560ms/step - loss: 0.5715 - accuracy: 0.7680 - val_loss: 0.4957 - val_accuracy: 0.8095\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 60s 609ms/step - loss: 0.5043 - accuracy: 0.8038 - val_loss: 0.4906 - val_accuracy: 0.7980\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 57s 575ms/step - loss: 0.4640 - accuracy: 0.8197 - val_loss: 0.3934 - val_accuracy: 0.8392\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 47s 475ms/step - loss: 0.4721 - accuracy: 0.8197 - val_loss: 0.6066 - val_accuracy: 0.7774\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 45s 462ms/step - loss: 0.4597 - accuracy: 0.8281 - val_loss: 0.4009 - val_accuracy: 0.8468\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 48s 486ms/step - loss: 0.4010 - accuracy: 0.8504 - val_loss: 0.3132 - val_accuracy: 0.8689\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 53s 536ms/step - loss: 0.3858 - accuracy: 0.8634 - val_loss: 0.3461 - val_accuracy: 0.8605\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 45s 461ms/step - loss: 0.3978 - accuracy: 0.8532 - val_loss: 0.2747 - val_accuracy: 0.8956\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 44s 451ms/step - loss: 0.3413 - accuracy: 0.8714 - val_loss: 0.3531 - val_accuracy: 0.8620\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 50s 508ms/step - loss: 0.3387 - accuracy: 0.8695 - val_loss: 0.3516 - val_accuracy: 0.8681\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 50s 510ms/step - loss: 0.3752 - accuracy: 0.8577 - val_loss: 0.3610 - val_accuracy: 0.8605\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 48s 493ms/step - loss: 0.3434 - accuracy: 0.8730 - val_loss: 0.3490 - val_accuracy: 0.8727\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 47s 480ms/step - loss: 0.3121 - accuracy: 0.8823 - val_loss: 0.2689 - val_accuracy: 0.9024\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 58s 589ms/step - loss: 0.2933 - accuracy: 0.8944 - val_loss: 0.1978 - val_accuracy: 0.9245\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 57s 577ms/step - loss: 0.2844 - accuracy: 0.8934 - val_loss: 0.2845 - val_accuracy: 0.8864\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 55s 565ms/step - loss: 0.2929 - accuracy: 0.8890 - val_loss: 0.3551 - val_accuracy: 0.8666\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 55s 564ms/step - loss: 0.2602 - accuracy: 0.9135 - val_loss: 0.2571 - val_accuracy: 0.9101\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 49s 493ms/step - loss: 0.2627 - accuracy: 0.9033 - val_loss: 0.2004 - val_accuracy: 0.9268\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 44s 451ms/step - loss: 0.2555 - accuracy: 0.9056 - val_loss: 0.1814 - val_accuracy: 0.9383\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 44s 450ms/step - loss: 0.2955 - accuracy: 0.8915 - val_loss: 0.2541 - val_accuracy: 0.9116\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 46s 473ms/step - loss: 0.2244 - accuracy: 0.9177 - val_loss: 0.1740 - val_accuracy: 0.9337\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 44s 445ms/step - loss: 0.2471 - accuracy: 0.9094 - val_loss: 0.2034 - val_accuracy: 0.9207\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 44s 449ms/step - loss: 0.2194 - accuracy: 0.9161 - val_loss: 0.1364 - val_accuracy: 0.9505\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 44s 447ms/step - loss: 0.2110 - accuracy: 0.9253 - val_loss: 0.2871 - val_accuracy: 0.8902\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 47s 482ms/step - loss: 0.1875 - accuracy: 0.9349 - val_loss: 0.0977 - val_accuracy: 0.9672\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 53s 534ms/step - loss: 0.1738 - accuracy: 0.9352 - val_loss: 0.2005 - val_accuracy: 0.9215\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 44s 449ms/step - loss: 0.1917 - accuracy: 0.9311 - val_loss: 0.1044 - val_accuracy: 0.9688\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 44s 446ms/step - loss: 0.1552 - accuracy: 0.9445 - val_loss: 0.1547 - val_accuracy: 0.9413\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 44s 446ms/step - loss: 0.2004 - accuracy: 0.9257 - val_loss: 0.3024 - val_accuracy: 0.8933\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 44s 445ms/step - loss: 0.1442 - accuracy: 0.9518 - val_loss: 0.1263 - val_accuracy: 0.9566\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 51s 517ms/step - loss: 0.2356 - accuracy: 0.9193 - val_loss: 0.1911 - val_accuracy: 0.9299\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 52s 534ms/step - loss: 0.1494 - accuracy: 0.9451 - val_loss: 0.0837 - val_accuracy: 0.9733\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 52s 532ms/step - loss: 0.1995 - accuracy: 0.9330 - val_loss: 0.1077 - val_accuracy: 0.9657\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 52s 526ms/step - loss: 0.1392 - accuracy: 0.9502 - val_loss: 0.3781 - val_accuracy: 0.8788\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 52s 528ms/step - loss: 0.1091 - accuracy: 0.9614 - val_loss: 0.1106 - val_accuracy: 0.9596\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 55s 559ms/step - loss: 0.1179 - accuracy: 0.9569 - val_loss: 0.0948 - val_accuracy: 0.9672\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 53s 540ms/step - loss: 0.1218 - accuracy: 0.9588 - val_loss: 0.0558 - val_accuracy: 0.9817\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 44s 445ms/step - loss: 0.1108 - accuracy: 0.9623 - val_loss: 0.0923 - val_accuracy: 0.9665\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 46s 470ms/step - loss: 0.1388 - accuracy: 0.9505 - val_loss: 0.0494 - val_accuracy: 0.9855\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 45s 458ms/step - loss: 0.0934 - accuracy: 0.9659 - val_loss: 0.0360 - val_accuracy: 0.9893\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 52s 532ms/step - loss: 0.0936 - accuracy: 0.9671 - val_loss: 0.0874 - val_accuracy: 0.9710\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 44s 449ms/step - loss: 0.0944 - accuracy: 0.9662 - val_loss: 0.1020 - val_accuracy: 0.9627\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 45s 463ms/step - loss: 0.1020 - accuracy: 0.9623 - val_loss: 0.0396 - val_accuracy: 0.9870\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 44s 444ms/step - loss: 0.0960 - accuracy: 0.9646 - val_loss: 0.0459 - val_accuracy: 0.9878\n",
      "42/42 - 5s - loss: 0.0458 - accuracy: 0.9878 - 5s/epoch - 109ms/step\n",
      "\n",
      "Test accuracy: 0.9878327250480652\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "data_dir = r\"C:\\Users\\Ananya\\Desktop\\bi-space-2d\\original\"\n",
    "img_width, img_height = 150, 150\n",
    "input_shape = (img_width, img_height, 3)\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "\n",
    "classes = ['p-early', 'p-bengin', 'p-pre', 'p-pro']\n",
    "\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(data_dir, cls)\n",
    "    images = [f for f in os.listdir(cls_dir) if os.path.isfile(os.path.join(cls_dir, f))]\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    \n",
    "    split_idx = int(0.8 * len(images))\n",
    "    \n",
    "    \n",
    "    for img in images[:split_idx]:\n",
    "        src = os.path.join(cls_dir, img)\n",
    "        dst = os.path.join(train_dir, cls, img)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    \n",
    "    for img in images[split_idx:]:\n",
    "        src = os.path.join(cls_dir, img)\n",
    "        dst = os.path.join(test_dir, cls, img)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97946c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2754 images belonging to 4 classes.\n",
      "Found 802 images belonging to 4 classes.\n",
      "Epoch 1/50\n",
      "86/86 [==============================] - 50s 562ms/step - loss: 0.7973 - accuracy: 0.6679 - val_loss: 0.5372 - val_accuracy: 0.8100\n",
      "Epoch 2/50\n",
      "86/86 [==============================] - 48s 561ms/step - loss: 0.5816 - accuracy: 0.7697 - val_loss: 0.5956 - val_accuracy: 0.7475\n",
      "Epoch 3/50\n",
      "86/86 [==============================] - 46s 533ms/step - loss: 0.5561 - accuracy: 0.7752 - val_loss: 0.4790 - val_accuracy: 0.8275\n",
      "Epoch 4/50\n",
      "86/86 [==============================] - 46s 537ms/step - loss: 0.4782 - accuracy: 0.8079 - val_loss: 0.4299 - val_accuracy: 0.8425\n",
      "Epoch 5/50\n",
      "86/86 [==============================] - 38s 444ms/step - loss: 0.4448 - accuracy: 0.8251 - val_loss: 0.3852 - val_accuracy: 0.8788\n",
      "Epoch 6/50\n",
      "86/86 [==============================] - 42s 482ms/step - loss: 0.4058 - accuracy: 0.8479 - val_loss: 0.3787 - val_accuracy: 0.8712\n",
      "Epoch 7/50\n",
      "86/86 [==============================] - 45s 518ms/step - loss: 0.3815 - accuracy: 0.8542 - val_loss: 0.3953 - val_accuracy: 0.8562\n",
      "Epoch 8/50\n",
      "86/86 [==============================] - 43s 498ms/step - loss: 0.3578 - accuracy: 0.8644 - val_loss: 0.3609 - val_accuracy: 0.8662\n",
      "Epoch 9/50\n",
      "86/86 [==============================] - 54s 627ms/step - loss: 0.3151 - accuracy: 0.8813 - val_loss: 0.2994 - val_accuracy: 0.9000\n",
      "Epoch 10/50\n",
      "86/86 [==============================] - 51s 587ms/step - loss: 0.2965 - accuracy: 0.8883 - val_loss: 0.2674 - val_accuracy: 0.9050\n",
      "Epoch 11/50\n",
      "86/86 [==============================] - 50s 582ms/step - loss: 0.2699 - accuracy: 0.9026 - val_loss: 0.2778 - val_accuracy: 0.8975\n",
      "Epoch 12/50\n",
      "86/86 [==============================] - 64s 750ms/step - loss: 0.2665 - accuracy: 0.9023 - val_loss: 0.2708 - val_accuracy: 0.9025\n",
      "Epoch 13/50\n",
      "86/86 [==============================] - 77s 886ms/step - loss: 0.2724 - accuracy: 0.8997 - val_loss: 0.3567 - val_accuracy: 0.8700\n",
      "Epoch 14/50\n",
      "86/86 [==============================] - 87s 1s/step - loss: 0.2372 - accuracy: 0.9159 - val_loss: 0.2656 - val_accuracy: 0.9112\n",
      "Epoch 15/50\n",
      "86/86 [==============================] - 85s 1000ms/step - loss: 0.2345 - accuracy: 0.9184 - val_loss: 0.2996 - val_accuracy: 0.8975\n",
      "Epoch 16/50\n",
      "86/86 [==============================] - 87s 1s/step - loss: 0.2204 - accuracy: 0.9232 - val_loss: 0.2424 - val_accuracy: 0.9125\n",
      "Epoch 17/50\n",
      "86/86 [==============================] - 73s 846ms/step - loss: 0.2113 - accuracy: 0.9265 - val_loss: 0.2754 - val_accuracy: 0.9013\n",
      "Epoch 18/50\n",
      "86/86 [==============================] - 77s 892ms/step - loss: 0.2049 - accuracy: 0.9229 - val_loss: 0.2477 - val_accuracy: 0.9100\n",
      "Epoch 19/50\n",
      "86/86 [==============================] - 75s 868ms/step - loss: 0.2017 - accuracy: 0.9291 - val_loss: 0.3019 - val_accuracy: 0.8875\n",
      "Epoch 20/50\n",
      "86/86 [==============================] - 80s 921ms/step - loss: 0.1785 - accuracy: 0.9364 - val_loss: 0.3215 - val_accuracy: 0.8975\n",
      "Epoch 21/50\n",
      "86/86 [==============================] - 77s 883ms/step - loss: 0.2109 - accuracy: 0.9166 - val_loss: 0.3087 - val_accuracy: 0.8988\n",
      "Epoch 22/50\n",
      "86/86 [==============================] - 70s 807ms/step - loss: 0.1840 - accuracy: 0.9379 - val_loss: 0.3687 - val_accuracy: 0.8775\n",
      "Epoch 23/50\n",
      "86/86 [==============================] - 72s 829ms/step - loss: 0.1581 - accuracy: 0.9453 - val_loss: 0.2366 - val_accuracy: 0.9200\n",
      "Epoch 24/50\n",
      "86/86 [==============================] - 85s 973ms/step - loss: 0.1773 - accuracy: 0.9416 - val_loss: 0.2310 - val_accuracy: 0.9187\n",
      "Epoch 25/50\n",
      "86/86 [==============================] - 85s 977ms/step - loss: 0.1560 - accuracy: 0.9412 - val_loss: 0.2262 - val_accuracy: 0.9237\n",
      "Epoch 26/50\n",
      "86/86 [==============================] - 87s 996ms/step - loss: 0.1585 - accuracy: 0.9445 - val_loss: 0.2258 - val_accuracy: 0.9262\n",
      "Epoch 27/50\n",
      "86/86 [==============================] - 82s 955ms/step - loss: 0.1193 - accuracy: 0.9581 - val_loss: 0.3430 - val_accuracy: 0.9075\n",
      "Epoch 28/50\n",
      "86/86 [==============================] - 94s 1s/step - loss: 0.1123 - accuracy: 0.9585 - val_loss: 0.5000 - val_accuracy: 0.8825\n",
      "Epoch 29/50\n",
      "86/86 [==============================] - 88s 1s/step - loss: 0.1471 - accuracy: 0.9493 - val_loss: 0.1960 - val_accuracy: 0.9400\n",
      "Epoch 30/50\n",
      "86/86 [==============================] - 86s 992ms/step - loss: 0.1126 - accuracy: 0.9596 - val_loss: 0.2681 - val_accuracy: 0.9237\n",
      "Epoch 31/50\n",
      "86/86 [==============================] - 88s 1s/step - loss: 0.1083 - accuracy: 0.9636 - val_loss: 0.2878 - val_accuracy: 0.9250\n",
      "Epoch 32/50\n",
      "86/86 [==============================] - 95s 1s/step - loss: 0.0951 - accuracy: 0.9651 - val_loss: 0.4103 - val_accuracy: 0.8975\n",
      "Epoch 33/50\n",
      "86/86 [==============================] - 84s 970ms/step - loss: 0.1024 - accuracy: 0.9640 - val_loss: 0.1717 - val_accuracy: 0.9525\n",
      "Epoch 34/50\n",
      "86/86 [==============================] - 82s 942ms/step - loss: 0.0875 - accuracy: 0.9702 - val_loss: 0.2497 - val_accuracy: 0.9300\n",
      "Epoch 35/50\n",
      "86/86 [==============================] - 89s 1s/step - loss: 0.0701 - accuracy: 0.9713 - val_loss: 0.2195 - val_accuracy: 0.9400\n",
      "Epoch 36/50\n",
      "86/86 [==============================] - 83s 956ms/step - loss: 0.0913 - accuracy: 0.9669 - val_loss: 0.3367 - val_accuracy: 0.9137\n",
      "Epoch 37/50\n",
      "86/86 [==============================] - 76s 881ms/step - loss: 0.0841 - accuracy: 0.9677 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
      "Epoch 38/50\n",
      "86/86 [==============================] - 75s 868ms/step - loss: 0.0940 - accuracy: 0.9699 - val_loss: 0.2309 - val_accuracy: 0.9375\n",
      "Epoch 39/50\n",
      "86/86 [==============================] - 78s 905ms/step - loss: 0.0677 - accuracy: 0.9805 - val_loss: 0.1766 - val_accuracy: 0.9575\n",
      "Epoch 40/50\n",
      "86/86 [==============================] - 95s 1s/step - loss: 0.0774 - accuracy: 0.9724 - val_loss: 0.2638 - val_accuracy: 0.9287\n",
      "Epoch 41/50\n",
      "86/86 [==============================] - 79s 914ms/step - loss: 0.0627 - accuracy: 0.9754 - val_loss: 0.2036 - val_accuracy: 0.9513\n",
      "Epoch 42/50\n",
      "86/86 [==============================] - 70s 805ms/step - loss: 0.0605 - accuracy: 0.9783 - val_loss: 0.1857 - val_accuracy: 0.9513\n",
      "Epoch 43/50\n",
      "86/86 [==============================] - 74s 859ms/step - loss: 0.0465 - accuracy: 0.9827 - val_loss: 0.2866 - val_accuracy: 0.9337\n",
      "Epoch 44/50\n",
      "86/86 [==============================] - 72s 826ms/step - loss: 0.0614 - accuracy: 0.9791 - val_loss: 0.2497 - val_accuracy: 0.9350\n",
      "Epoch 45/50\n",
      "86/86 [==============================] - 96s 1s/step - loss: 0.0853 - accuracy: 0.9728 - val_loss: 0.1647 - val_accuracy: 0.9525\n",
      "Epoch 46/50\n",
      "86/86 [==============================] - 91s 1s/step - loss: 0.0453 - accuracy: 0.9827 - val_loss: 0.2170 - val_accuracy: 0.9438\n",
      "Epoch 47/50\n",
      "86/86 [==============================] - 95s 1s/step - loss: 0.0621 - accuracy: 0.9780 - val_loss: 0.2029 - val_accuracy: 0.9463\n",
      "Epoch 48/50\n",
      "86/86 [==============================] - 77s 889ms/step - loss: 0.0646 - accuracy: 0.9772 - val_loss: 0.3804 - val_accuracy: 0.9212\n",
      "Epoch 49/50\n",
      "86/86 [==============================] - 70s 805ms/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.2125 - val_accuracy: 0.9575\n",
      "Epoch 50/50\n",
      "86/86 [==============================] - 88s 1s/step - loss: 0.0448 - accuracy: 0.9842 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
      "26/26 - 6s - loss: 0.1938 - accuracy: 0.9426 - 6s/epoch - 236ms/step\n",
      "\n",
      "Test accuracy: 0.942643404006958\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "data_dir = r\"C:\\Users\\Ananya\\Desktop\\bi-space-2d\\segmented\"\n",
    "img_width, img_height = 150, 150\n",
    "input_shape = (img_width, img_height, 3)\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "\n",
    "classes = ['p-early', 'p-benign', 'p-pre', 'p-pro']\n",
    "\n",
    "\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(data_dir, cls)\n",
    "    images = [f for f in os.listdir(cls_dir) if os.path.isfile(os.path.join(cls_dir, f))]\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    \n",
    "    split_idx = int(0.8 * len(images))\n",
    "    \n",
    "    \n",
    "    for img in images[:split_idx]:\n",
    "        src = os.path.join(cls_dir, img)\n",
    "        dst = os.path.join(train_dir, cls, img)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    \n",
    "    for img in images[split_idx:]:\n",
    "        src = os.path.join(cls_dir, img)\n",
    "        dst = os.path.join(test_dir, cls, img)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff179e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
